[{"content":"\u003cp\u003eThis project is created with the intention of fulfiling my curiosity. Some of the questions that I hope that I can answer by doing this project is:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eWhat \u003cem\u003etype\u003c/em\u003e of person is interested in subscribing to a term deposit?\u003c/li\u003e\n\u003cli\u003eWith the assumption of using just calls to tell them about term deposit, is the action of just calling enough to persuade them? If it is enough what is the minimum time needed to know we have somewhat persuaded the person?\u003c/li\u003e\n\u003cli\u003eBetween Logistic Regression and Support Machine Vector, which one is better?\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThe dataset that I am gona use is from a Portuguese banking institution marketing campaign. The goal of this dataset is to classify if the client will subscribe a term deposit. The original format of this file is \u003ccode\u003e.arff\u003c/code\u003e format which is suitable for machine learning and easier for machines to read.\u003c/p\u003e\n\u003cp\u003eTo keep things simple I\u0026rsquo;m going to use only Logistic Regression and Support Machine Vector, another reason why I\u0026rsquo;m using only these models is to learn the workings of both models. At the end I\u0026rsquo;m going to compare its accuracy, to determine which is better. The results of this comparison is quite surprising.\u003c/p\u003e\n\u003ch2 id=\"cleaning-data\"\u003eCleaning Data\u003c/h2\u003e\n\u003cp\u003eTaking a quick look at the data it\u0026rsquo;s header are named using variables names, \u003ccode\u003eV1, V2,...\u003c/code\u003e because of this I first changed its headers to its associated description.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eBefore Transformation\u003c/em\u003e\n\u003cimg src=\"headers_bf.png\" alt=\"Transforming Headers Before\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eAfter Transformation\u003c/em\u003e\n\u003cimg src=\"headers_af.png\" alt=\"Transforming Headers After\"\u003e\u003c/p\u003e\n\u003cp\u003eAfter that I changed the \u003ccode\u003elast_contact_day\u003c/code\u003e and \u003ccode\u003elast_contact_month\u003c/code\u003e to become one column calling it \u003ccode\u003elast_contact_date\u003c/code\u003e. The reason for this change is because I found it a bit weird as to why it isn\u0026rsquo;t combined to a single day. Additionally I added a line of code to change datetime to ordinal, to fit with the linear regression model.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eBefore Transformation\u003c/em\u003e\n\u003cimg src=\"date_bf.png\" alt=\"Transforming dates Before\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eAfter Transformation\u003c/em\u003e\n\u003cimg src=\"date_af.png\" alt=\"Transforming dates after\"\u003e\u003c/p\u003e\n\u003cp\u003eThen I changed the target \u003ccode\u003eY\u003c/code\u003e which is the \u003ccode\u003eterm_deposit\u003c/code\u003e column, for some odd reason its in 1 and 2. Which I personally found weird and didn\u0026rsquo;t like it, so I applied \u003ccode\u003eOrdinalEncoder\u003c/code\u003e to become 0 and 1.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eBefore Transformation\u003c/em\u003e\n\u003cimg src=\"y_bf.png\" alt=\"Transforming term_deposit\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eAfter Transformation\u003c/em\u003e\n\u003cimg src=\"y_af.png\" alt=\"Transforming term_deposit\"\u003e\u003c/p\u003e\n\u003cp\u003eFinally, some columns are categorical. I have thought of just using \u003ccode\u003eOrdinalEncoder\u003c/code\u003e but that will lead to the interpretation that it has a hierarchy, when there isn\u0026rsquo;t. So I use \u003ccode\u003eOneHotEncoder\u003c/code\u003e class which transforms the these columns into a 1-column matrix, where each column is either \u003ccode\u003e0\u003c/code\u003e or \u003ccode\u003e1\u003c/code\u003e, where \u003ccode\u003e0\u003c/code\u003e mean \u0026ldquo;it doesn\u0026rsquo;t belong to his category\u0026rdquo; while \u003ccode\u003e1\u003c/code\u003e is the opposite. In this matrix there can only be one \u003ccode\u003e1\u003c/code\u003e value.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eBefore Transformation\u003c/em\u003e\n\u003cimg src=\"categorical_bf.png\" alt=\"Transforming Categorical\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eAfter Transformation\u003c/em\u003e\n\u003cimg src=\"categorical_af.png\" alt=\"Transforming Categorical\"\u003e\u003c/p\u003e\n\u003cp\u003eNote: After dealing with the categorical data, there were some other small changes to the dataframe which was converting floating data types to integer and re-indexing \u003ccode\u003eterm_deposit\u003c/code\u003e to be the last column instead of the middle (this is due to transformations).\u003c/p\u003e\n\u003ch2 id=\"explaratory-data-analysis\"\u003eExplaratory Data Analysis\u003c/h2\u003e\n\u003cp\u003eBefore creating and evaluating models, I would like to see how the data is there any correlation with the feautures with the target, and see if any has a significant effect on it.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"corr_plot.png\" alt=\"Correlation plot\"\u003e\u003c/p\u003e\n\u003cp\u003eFrom the correlation matrix above (\u003ca href=\"https://github.com/Just1a2Noob/Independent_Projects/blob/main/bank%20marketing/bank-marketing.ipynb\"\u003eoriginal image\u003c/a\u003e) we can see only a few features actually has a correlation with our target (\u003ccode\u003eterm_deposit\u003c/code\u003e).\u003c/p\u003e\n\u003cp\u003eNext, I\u0026rsquo;m checking if the dataset is skewed or normally distributed. To do this I use boxplots on numerical data, not data that has been converted to date or binary.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"boxplot1.png\" alt=\"boxplot1\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"boxplot2.png\" alt=\"boxplot2\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"boxplot3.png\" alt=\"boxplot3\"\u003e\u003c/p\u003e\n\u003cp\u003eFrom the boxplots above we can see that the dataset is somewhat skewed. Meaning this dataset \u003cstrong\u003eisn\u0026rsquo;t normally distributed\u003c/strong\u003e.\u003c/p\u003e\n\u003ch2 id=\"model-training\"\u003eModel Training\u003c/h2\u003e\n\u003ch3 id=\"logistic-regression\"\u003eLogistic Regression\u003c/h3\u003e\n\u003cp\u003eWhen creating the logistic regression model, I used scikit-learn\u0026rsquo;s \u003ccode\u003eLogisticRegression\u003c/code\u003e class and for evaluating the both models I used both \u003ccode\u003eaccuracy_score\u003c/code\u003e and \u003ccode\u003eroc_auc_score\u003c/code\u003e. Additionally the \u003ccode\u003epenalty\u003c/code\u003e parameter is set to \u003ccode\u003el1\u003c/code\u003e due to the dataset being skewed and being wary of outliers.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eparam_distributions \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;penalty\u0026#39;\u003c/span\u003e: [\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;l1\u0026#39;\u003c/span\u003e],\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;tol\u0026#39;\u003c/span\u003e: [\u003cspan style=\"color:#ae81ff\"\u003e1e-3\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e1e-4\u003c/span\u003e],\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;C\u0026#39;\u003c/span\u003e: loguniform(\u003cspan style=\"color:#ae81ff\"\u003e0.01\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e100\u003c/span\u003e),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;solver\u0026#39;\u003c/span\u003e: [\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;liblinear\u0026#39;\u003c/span\u003e, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;saga\u0026#39;\u003c/span\u003e],\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;max_iter\u0026#39;\u003c/span\u003e: [\u003cspan style=\"color:#ae81ff\"\u003e1000\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e2000\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e5000\u003c/span\u003e] \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eWhen splitting the data, I use the \u003ccode\u003eStratefiedKFold\u003c/code\u003e class to split the data. The reason for using \u003ccode\u003eStratefiedKFold\u003c/code\u003e is make the evaluation more robust and the computational load isn\u0026rsquo;t big.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eskf \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e StratifiedKFold(n_splits\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e5\u003c/span\u003e, shuffle\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e, random_state\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e42\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003efold \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eaucs \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e []\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eaccuracies \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e []\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# Loop through the splits generated by StratifiedKFold\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e train_index, test_index \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e skf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esplit(features, target):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    X_train, X_test \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e features\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eiloc[train_index], features\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eiloc[test_index]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    y_train, y_test \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e target\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eiloc[train_index], target\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eiloc[test_index]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e# Create a copy of the best model (to maintain independence between folds)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e# Using the best parameters found by RandomizedSearchCV\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    fold_model \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e LogisticRegression(\u003cspan style=\"color:#f92672\"\u003e**\u003c/span\u003ebest_log_reg\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eget_params())\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    fold_model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efit(X_train, y_train\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003evalues\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eravel())\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    logreg_y_pred \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e fold_model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epredict(X_test)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    logreg_y_pred_prob \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e fold_model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epredict_proba(X_test)[:, \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    logreg_acc_score \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e accuracy_score(y_test, logreg_y_pred)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    logreg_auc_score \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e roc_auc_score(y_test, logreg_y_pred_prob)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    print(\u003cspan style=\"color:#e6db74\"\u003ef\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;======= Fold \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e{\u003c/span\u003efold\u003cspan style=\"color:#e6db74\"\u003e}\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e ========\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    print(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#e6db74\"\u003ef\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Accuracy on the validation set is \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e{\u003c/span\u003elogreg_acc_score\u003cspan style=\"color:#e6db74\"\u003e:\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e0.4f\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e}\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e and AUC is \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e{\u003c/span\u003elogreg_auc_score\u003cspan style=\"color:#e6db74\"\u003e:\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e0.4f\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e}\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    )\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    fold \u003cspan style=\"color:#f92672\"\u003e+=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    aucs\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eappend(logreg_auc_score)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    accuracies\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eappend(logreg_acc_score)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# Calculate and print average performance metrics\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003elogreg_avg_auc \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e np\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003emean(aucs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003elogreg_avg_accuracy \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e np\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003emean(accuracies)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprint(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\n\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprint(\u003cspan style=\"color:#e6db74\"\u003ef\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Average AUC score is \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e{\u003c/span\u003elogreg_avg_auc\u003cspan style=\"color:#e6db74\"\u003e:\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e0.4f\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e}\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprint(\u003cspan style=\"color:#e6db74\"\u003ef\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Average Accuracy score is \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e{\u003c/span\u003elogreg_avg_accuracy\u003cspan style=\"color:#e6db74\"\u003e:\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e0.4f\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e}\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThe loop in the code block above is way to print out its results of accuracy and auc score after each split.\u003c/p\u003e\n\u003ch3 id=\"support-machine-vector\"\u003eSupport Machine Vector\u003c/h3\u003e\n\u003cp\u003eFor Support Machine Vector I use the the \u003ccode\u003eLinearSVC\u003c/code\u003e class from scikit-learn, the reason I use this class instead of \u003ccode\u003eSVC\u003c/code\u003e or \u003ccode\u003eSGDClassifier\u003c/code\u003e is because typically its much more faster than \u003ccode\u003eSVC\u003c/code\u003e and it\u0026rsquo;s more efficient for linear boundaries.\u003c/p\u003e\n\u003cp\u003eWhen creating the hyprparameter tuning for \u003ccode\u003eLinearSVC\u003c/code\u003e, the penalty is \u003ccode\u003el2\u003c/code\u003e same as the Logistic Regression model with the same reasons.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eparam_distributions \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;C\u0026#39;\u003c/span\u003e: loguniform(\u003cspan style=\"color:#ae81ff\"\u003e0.01\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e100\u003c/span\u003e),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;loss\u0026#39;\u003c/span\u003e: [\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;hinge\u0026#39;\u003c/span\u003e, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;squared_hinge\u0026#39;\u003c/span\u003e],\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;penalty\u0026#39;\u003c/span\u003e: [\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;l2\u0026#39;\u003c/span\u003e],\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;tol\u0026#39;\u003c/span\u003e: loguniform(\u003cspan style=\"color:#ae81ff\"\u003e1e-5\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e1e-3\u003c/span\u003e),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;max_iter\u0026#39;\u003c/span\u003e: [\u003cspan style=\"color:#ae81ff\"\u003e1000\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e2000\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e5000\u003c/span\u003e] \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eIn the case of \u003ccode\u003eLinearSVC\u003c/code\u003e model, I split the data into three: train, validation, test. The reason for not using \u003ccode\u003eStratefiedKFold\u003c/code\u003e is mainly because it\u0026rsquo;s computionally inefficient. I assumed I have enough data to use split data without losing a significant amount of evaluation loss. But it does increase the chances of the split being \u0026lsquo;unlucky\u0026rsquo;, which can mean increase of bias or decrease/increase of variance in a single split.\u003c/p\u003e\n\u003ch2 id=\"model-evaluation\"\u003eModel Evaluation\u003c/h2\u003e\n\u003cp\u003eFor model evaluation, I used accuracy as the main comparison between the both of them but I will provide both both models AUC score.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"model_compare.png\" alt=\"Accuracy Comparison\"\u003e\u003c/p\u003e\n\u003cp\u003eFrom the graph above we can see that both models are nearly the same with only a 0.03 difference between. Meaning in terms of accuracy it can be said that both are them same (due to the small difference). This conclusion shouldn\u0026rsquo;t come to a surprise because both the \u003ccode\u003eLinearSVC\u003c/code\u003e implements \u003cem\u003eregularized\u003c/em\u003e logistic regression using different libraries (which allows more flexibility).\u003c/p\u003e\n\u003cp\u003eBelow is both models accuracy and AUC score:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eModel\u003c/th\u003e\n\u003cth\u003eAUC\u003c/th\u003e\n\u003cth\u003eAccuracy\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eLogisticRegression\u003c/td\u003e\n\u003ctd\u003e0.8202\u003c/td\u003e\n\u003ctd\u003e0.887\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLinearSVC\u003c/td\u003e\n\u003ctd\u003e0.8925\u003c/td\u003e\n\u003ctd\u003e0.90\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n","description":"","image":null,"permalink":"http://localhost:1313/blogs/svm_linear/","title":"Can Logistic Regression Compete with LinearSVC? Predicting Term Deposit Signups with Bank Data"}]